{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00187238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:27:57.520412Z",
     "iopub.status.busy": "2024-02-07T21:27:57.520013Z",
     "iopub.status.idle": "2024-02-07T21:28:01.736666Z",
     "shell.execute_reply": "2024-02-07T21:28:01.735326Z"
    },
    "papermill": {
     "duration": 4.227484,
     "end_time": "2024-02-07T21:28:01.739621",
     "exception": false,
     "start_time": "2024-02-07T21:27:57.512137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ROOT = Path('/home/sabina.jangirova/Documents/ML703_project/data')\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b1f90b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:28:01.755445Z",
     "iopub.status.busy": "2024-02-07T21:28:01.755022Z",
     "iopub.status.idle": "2024-02-07T21:28:01.764738Z",
     "shell.execute_reply": "2024-02-07T21:28:01.763428Z"
    },
    "papermill": {
     "duration": 0.020544,
     "end_time": "2024-02-07T21:28:01.767089",
     "exception": false,
     "start_time": "2024-02-07T21:28:01.746545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "\n",
    "    def set_table_dtypes(df):\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date,strict=False))\n",
    "        return df\n",
    "\n",
    "    def handle_dates(df):\n",
    "        for col in df.columns: \n",
    "                if col.endswith(\"D\"):\n",
    "                    # Calculate the difference in days between each date column and date_decision\n",
    "                    df = df.with_columns(\n",
    "                        (pl.col(\"date_decision\") - pl.col(col)).dt.total_days().alias(col)\n",
    "                    )\n",
    "                    df = df.with_columns(pl.col(col).fill_null(np.nan)) \n",
    "        # Drop date_decision column\n",
    "        df = df.drop(\"date_decision\")\n",
    "#         print(df.dtypes) # for Debugging\n",
    "        return df\n",
    "\n",
    "    def filter_cols(df,base_df = None,test=False):\n",
    "        #for test data\n",
    "            for col in df.columns:\n",
    "                if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n",
    "                    isnull = df[col].is_null().mean()\n",
    "                    if isnull > 0.7:\n",
    "                        df = df.drop(col)\n",
    "            columns_to_drop = []\n",
    "            for col in df.columns:\n",
    "                if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n",
    "                    freq = df[col].n_unique()\n",
    "                    if (freq == 1) or (freq > 100):\n",
    "                        columns_to_drop.append(col)\n",
    "\n",
    "            df = df.drop(columns_to_drop)\n",
    "            return df\n",
    "\n",
    "\n",
    "class Aggregator:\n",
    "    \n",
    "    @staticmethod\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def date_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"D\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def str_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def other_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def count_expr(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" in col]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df) + \\\n",
    "                Aggregator.date_expr(df) + \\\n",
    "                Aggregator.str_expr(df) + \\\n",
    "                Aggregator.other_expr(df) + \\\n",
    "                Aggregator.count_expr(df)\n",
    "        return exprs\n",
    "\n",
    "def read_file(path, depth=None):\n",
    "    df = pl.read_parquet(path)\n",
    "    df = df.pipe(Pipeline.set_table_dtypes)\n",
    "    if depth in [1,2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df)) \n",
    "    return df\n",
    "\n",
    "def read_files(regex_path, depth=None):\n",
    "    chunks = []\n",
    "    for path in glob(str(regex_path)):\n",
    "        df = pl.read_parquet(path)\n",
    "        df = df.pipe(Pipeline.set_table_dtypes)\n",
    "        if depth in [1, 2]:\n",
    "            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "        chunks.append(df)\n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    df = df.unique(subset=[\"case_id\"])\n",
    "    return df\n",
    "\n",
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    df_base = (\n",
    "        df_base\n",
    "        .with_columns(\n",
    "            month_decision = pl.col(\"date_decision\").dt.month(),\n",
    "            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "    df_base = df_base.pipe(Pipeline.set_table_dtypes)\n",
    "    df_base = df_base.pipe(Pipeline.handle_dates)\n",
    "    return df_base\n",
    "\n",
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas()\n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n",
    "    return df_data, cat_cols\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if str(col_type)==\"category\":\n",
    "            continue\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                try:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)\n",
    "                except:\n",
    "                    continue\n",
    "        else:\n",
    "            continue\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016b91f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:28:01.782683Z",
     "iopub.status.busy": "2024-02-07T21:28:01.782161Z",
     "iopub.status.idle": "2024-02-07T21:28:20.978046Z",
     "shell.execute_reply": "2024-02-07T21:28:20.977092Z"
    },
    "papermill": {
     "duration": 19.207089,
     "end_time": "2024-02-07T21:28:20.980847",
     "exception": false,
     "start_time": "2024-02-07T21:28:01.773758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR        = ROOT / \"parquet_files\" / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8d8336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:28:20.996615Z",
     "iopub.status.busy": "2024-02-07T21:28:20.995823Z",
     "iopub.status.idle": "2024-02-07T21:28:21.064631Z",
     "shell.execute_reply": "2024-02-07T21:28:21.063597Z"
    },
    "metadata": {},
    "papermill": {
     "duration": 0.079736,
     "end_time": "2024-02-07T21:28:21.067361",
     "exception": false,
     "start_time": "2024-02-07T21:28:20.987625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 39s, sys: 1min 43s, total: 5min 23s\n",
      "Wall time: 44.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_store = {\n",
    "    \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "        read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_applprev_2.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_person_2.parquet\", 2)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da15e81",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\t (1526659, 488)\n",
      "Memory usage of dataframe is 3313.73 MB\n",
      "Memory usage after optimization is: 1097.80 MB\n",
      "Decreased by 66.9%\n",
      "train data shape:\t (1526659, 344)\n",
      "Use these ['case_id', 'WEEK_NUM', 'target', 'month_decision', 'weekday_decision', 'credamount_770A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_867L', 'clientscnt_1022L', 'clientscnt_100L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'deferredmnthsnum_166L', 'disbursedcredamount_1113A', 'downpmt_116A', 'homephncnt_628L', 'isbidproduct_1095L', 'mobilephncnt_593L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'sellerplacecnt_915L', 'max_mainoccupationinc_384A', 'max_birth_259D', 'max_num_group1_9']\n",
      "####### NAN count = 0\n",
      "####### NAN count = 1389663\n",
      "####### NAN count = 1411681\n",
      "####### NAN count = 1455026\n",
      "####### NAN count = 918788\n",
      "Use these ['dateofbirth_337D', 'days180_256L', 'days30_165L', 'days360_512L', 'firstquarter_103L', 'fourthquarter_440L', 'secondquarter_766L', 'thirdquarter_1082L', 'max_debtoutstand_525A', 'max_debtoverdue_47A', 'max_refreshdate_3813885D']\n",
      "####### NAN count = 140968\n",
      "####### NAN count = 1490159\n",
      "Use these ['pmtscount_423L', 'pmtssum_45A']\n",
      "####### NAN count = 954021\n",
      "####### NAN count = 806659\n",
      "####### NAN count = 866332\n",
      "####### NAN count = 1301747\n",
      "####### NAN count = 418178\n",
      "Use these ['amtinstpaidbefduel24m_4187115A', 'numinstlswithdpd5_4187116L']\n",
      "####### NAN count = 561124\n",
      "Use these ['annuitynextmonth_57A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'numinstls_657L', 'totalsettled_863A']\n",
      "####### NAN count = 4\n",
      "Use these ['mindbddpdlast24m_3658935P']\n",
      "####### NAN count = 613202\n",
      "####### NAN count = 948244\n",
      "Use these ['mindbdtollast24m_4525191P']\n",
      "####### NAN count = 972827\n",
      "####### NAN count = 467175\n",
      "Use these ['avginstallast24m_3658937A', 'maxinstallast24m_3658928A']\n",
      "####### NAN count = 624875\n",
      "####### NAN count = 757006\n",
      "####### NAN count = 841181\n",
      "####### NAN count = 1026987\n",
      "####### NAN count = 455190\n",
      "####### NAN count = 460822\n",
      "Use these ['commnoinclast6m_3546845L', 'maxdpdfrom6mto36m_3546853P']\n",
      "####### NAN count = 343375\n",
      "####### NAN count = 833735\n",
      "####### NAN count = 1392841\n",
      "####### NAN count = 887659\n",
      "Use these ['daysoverduetolerancedd_3976961L', 'numinsttopaygr_769L']\n",
      "####### NAN count = 452594\n",
      "####### NAN count = 977119\n",
      "Use these ['eir_270L']\n",
      "####### NAN count = 190833\n",
      "####### NAN count = 859214\n",
      "####### NAN count = 482103\n",
      "####### NAN count = 453587\n",
      "Use these ['lastapplicationdate_877D', 'max_num_group1', 'max_num_group2_14']\n",
      "####### NAN count = 305137\n",
      "Use these ['lastapprcredamount_781A', 'lastapprdate_640D']\n",
      "####### NAN count = 442041\n",
      "####### NAN count = 977975\n",
      "Use these ['lastrejectcredamount_222A', 'lastrejectdate_50D']\n",
      "####### NAN count = 769046\n",
      "####### NAN count = 1524282\n",
      "####### NAN count = 511255\n",
      "Use these ['mastercontrelectronic_519L', 'mastercontrexist_109L', 'maxannuity_159A', 'maxdebt4_972A', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdtolerance_374P']\n",
      "####### NAN count = 306019\n",
      "####### NAN count = 960953\n",
      "####### NAN count = 705504\n",
      "####### NAN count = 876276\n",
      "####### NAN count = 826000\n",
      "####### NAN count = 829402\n",
      "####### NAN count = 1032856\n",
      "####### NAN count = 766958\n",
      "Use these ['numinstpaidearly_338L', 'numinstpaidearly5d_1087L', 'numinstpaidlate1d_3546852L']\n",
      "####### NAN count = 452593\n",
      "####### NAN count = 455081\n",
      "Use these ['numinstlsallpaid_934L']\n",
      "####### NAN count = 445669\n",
      "Use these ['numinstlswithdpd10_728L', 'numinstlswithoutdpd_562L']\n",
      "####### NAN count = 456495\n",
      "Use these ['numinstpaid_4499208L']\n",
      "####### NAN count = 847191\n",
      "####### NAN count = 446983\n",
      "Use these ['numinstregularpaidest_4493210L', 'numinstpaidearly5dest_4493211L', 'sumoutstandtotalest_4493215A']\n",
      "####### NAN count = 840646\n",
      "####### NAN count = 669186\n",
      "####### NAN count = 455612\n",
      "####### NAN count = 1517330\n",
      "Use these ['pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlate1d_3546856L']\n",
      "####### NAN count = 458738\n",
      "####### NAN count = 461362\n",
      "####### NAN count = 459827\n",
      "####### NAN count = 460079\n",
      "####### NAN count = 44954\n",
      "####### NAN count = 78526\n",
      "####### NAN count = 131888\n",
      "####### NAN count = 181122\n",
      "####### NAN count = 223240\n",
      "####### NAN count = 445320\n",
      "####### NAN count = 3\n",
      "####### NAN count = 1374886\n",
      "####### NAN count = 305154\n",
      "####### NAN count = 308739\n",
      "Use these ['max_credacc_credlmt_575A', 'max_credamount_590A', 'max_downpmt_134A']\n",
      "####### NAN count = 307441\n",
      "####### NAN count = 419006\n",
      "####### NAN count = 306361\n",
      "####### NAN count = 450969\n",
      "####### NAN count = 420383\n",
      "####### NAN count = 442999\n",
      "####### NAN count = 454678\n",
      "####### NAN count = 703840\n",
      "####### NAN count = 548987\n",
      "####### NAN count = 559169\n",
      "####### NAN count = 334873\n",
      "####### NAN count = 961606\n",
      "####### NAN count = 552766\n",
      "Use these ['max_pmtnum_8L']\n",
      "####### NAN count = 321446\n",
      "####### NAN count = 1068725\n",
      "####### NAN count = 1375927\n",
      "Use these ['max_pmtamount_36A', 'max_processingdate_168D', 'max_num_group1_5']\n",
      "####### NAN count = 1044394\n",
      "####### NAN count = 1036944\n",
      "####### NAN count = 603001\n",
      "Use these ['max_dpdmax_139P', 'max_dpdmaxdatemonth_89T', 'max_dpdmaxdateyear_596T']\n",
      "####### NAN count = 263166\n",
      "Use these ['max_pmts_dpd_303P', 'max_dpdmaxdatemonth_442T', 'max_dpdmaxdateyear_896T']\n",
      "####### NAN count = 514070\n",
      "####### NAN count = 606920\n",
      "####### NAN count = 263233\n",
      "####### NAN count = 517511\n",
      "####### NAN count = 545885\n",
      "####### NAN count = 636453\n",
      "####### NAN count = 512650\n",
      "Use these ['max_overdueamount_659A', 'max_numberofoverdueinstls_725L']\n",
      "####### NAN count = 263171\n",
      "Use these ['max_overdueamountmax2_14A', 'max_totaloutstanddebtvalue_39A', 'max_dateofcredend_289D', 'max_dateofcredstart_739D', 'max_lastupdate_1112D', 'max_numberofcontrsvalue_258L', 'max_numberofoverdueinstlmax_1039L', 'max_overdueamountmaxdatemonth_365T', 'max_overdueamountmaxdateyear_2T', 'max_pmts_month_158T', 'max_pmts_year_1139T']\n",
      "####### NAN count = 262653\n",
      "Use these ['max_overdueamountmax2_398A', 'max_dateofcredend_353D', 'max_dateofcredstart_181D', 'max_numberofoverdueinstlmax_1151L']\n",
      "####### NAN count = 512590\n",
      "Use these ['max_overdueamountmax_35A', 'max_overdueamountmaxdatemonth_284T', 'max_overdueamountmaxdateyear_994T']\n",
      "####### NAN count = 513987\n",
      "####### NAN count = 1039597\n",
      "####### NAN count = 606900\n",
      "####### NAN count = 545855\n",
      "####### NAN count = 636448\n",
      "Use these ['max_totaldebtoverduevalue_718A', 'max_totaloutstanddebtvalue_668A', 'max_numberofcontrsvalue_358L']\n",
      "####### NAN count = 297072\n",
      "####### NAN count = 512961\n",
      "####### NAN count = 512591\n",
      "####### NAN count = 802351\n",
      "####### NAN count = 1012361\n",
      "####### NAN count = 806653\n",
      "####### NAN count = 1007594\n",
      "####### NAN count = 822517\n",
      "####### NAN count = 745109\n",
      "####### NAN count = 545898\n",
      "####### NAN count = 636545\n",
      "####### NAN count = 545895\n",
      "####### NAN count = 636544\n",
      "####### NAN count = 512657\n",
      "####### NAN count = 561307\n",
      "####### NAN count = 649082\n",
      "####### NAN count = 140386\n",
      "Use these ['max_contractdate_551D', 'max_pmts_date_1107D']\n",
      "####### NAN count = 1490212\n",
      "####### NAN count = 1490235\n",
      "####### NAN count = 1514201\n",
      "####### NAN count = 959958\n",
      "####### NAN count = 1467040\n",
      "####### NAN count = 1421548\n",
      "####### NAN count = 1421572\n",
      "####### NAN count = 262659\n",
      "####### NAN count = 512884\n",
      "Use these ['max_pmts_month_706T', 'max_pmts_year_507T']\n",
      "####### NAN count = 512598\n",
      "Use these ['max_num_group1_13', 'max_num_group2_13']\n",
      "####### NAN count = 141371\n",
      "####### NAN count = 1520903\n",
      "Use these ['max_num_group1_15', 'max_num_group2_15']\n",
      "####### NAN count = 91554\n",
      "['case_id', 'WEEK_NUM', 'target', 'month_decision', 'weekday_decision', 'credamount_770A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_867L', 'clientscnt_1022L', 'clientscnt_100L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'deferredmnthsnum_166L', 'disbursedcredamount_1113A', 'downpmt_116A', 'homephncnt_628L', 'isbidproduct_1095L', 'mobilephncnt_593L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'sellerplacecnt_915L', 'max_mainoccupationinc_384A', 'max_birth_259D', 'max_num_group1_9', 'assignmentdate_238D', 'assignmentdate_4527235D', 'assignmentdate_4955616D', 'birthdate_574D', 'dateofbirth_337D', 'days180_256L', 'days30_165L', 'days360_512L', 'firstquarter_103L', 'fourthquarter_440L', 'secondquarter_766L', 'thirdquarter_1082L', 'max_debtoutstand_525A', 'max_debtoverdue_47A', 'max_refreshdate_3813885D', 'dateofbirth_342D', 'pmtscount_423L', 'pmtssum_45A', 'responsedate_1012D', 'responsedate_4527233D', 'responsedate_4917613D', 'actualdpdtolerance_344P', 'amtinstpaidbefduel24m_4187115A', 'numinstlswithdpd5_4187116L', 'annuitynextmonth_57A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'numinstls_657L', 'totalsettled_863A', 'mindbddpdlast24m_3658935P', 'avgdbddpdlast3m_4187120P', 'mindbdtollast24m_4525191P', 'avgdpdtolclosure24_3658938P', 'avginstallast24m_3658937A', 'maxinstallast24m_3658928A', 'avgmaxdpdlast9m_3716943P', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'cntincpaycont9m_3716944L', 'cntpmts24_3658933L', 'commnoinclast6m_3546845L', 'maxdpdfrom6mto36m_3546853P', 'datefirstoffer_1144D', 'datelastinstal40dpd_247D', 'datelastunpaid_3546854D', 'daysoverduetolerancedd_3976961L', 'numinsttopaygr_769L', 'dtlastpmtallstes_4499206D', 'eir_270L', 'firstclxcampaign_1125D', 'firstdatedue_489D', 'lastactivateddate_801D', 'lastapplicationdate_877D', 'max_num_group1', 'max_num_group2_14', 'lastapprcredamount_781A', 'lastapprdate_640D', 'lastdelinqdate_224D', 'lastrejectcredamount_222A', 'lastrejectdate_50D', 'lastrepayingdate_696D', 'maininc_215A', 'mastercontrelectronic_519L', 'mastercontrexist_109L', 'maxannuity_159A', 'maxdebt4_972A', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdtolerance_374P', 'maxdbddpdlast1m_3658939P', 'maxdbddpdtollast12m_3658940P', 'maxdbddpdtollast6m_4187119P', 'maxdpdinstldate_3546855D', 'maxdpdinstlnum_3546846P', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'numinstpaidearly_338L', 'numinstpaidearly5d_1087L', 'numinstpaidlate1d_3546852L', 'numincomingpmts_3546848L', 'numinstlsallpaid_934L', 'numinstlswithdpd10_728L', 'numinstlswithoutdpd_562L', 'numinstpaid_4499208L', 'numinstpaidearly3d_3546850L', 'numinstregularpaidest_4493210L', 'numinstpaidearly5dest_4493211L', 'sumoutstandtotalest_4493215A', 'numinstpaidlastcontr_4325080L', 'numinstregularpaid_973L', 'payvacationpostpone_4187118D', 'pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlate1d_3546856L', 'pctinstlsallpaidlat10d_839L', 'pctinstlsallpaidlate4d_3546849L', 'pctinstlsallpaidlate6d_3546844L', 'pmtnum_254L', 'posfpd10lastmonth_333P', 'posfpd30lastmonth_3976960P', 'posfstqpd30lastmonth_3976962P', 'price_1097A', 'sumoutstandtotal_3546847A', 'totaldebt_9A', 'validfrom_1069D', 'max_actualdpd_943P', 'max_annuity_853A', 'max_credacc_credlmt_575A', 'max_credamount_590A', 'max_downpmt_134A', 'max_currdebt_94A', 'max_mainoccupationinc_437A', 'max_maxdpdtolerance_577P', 'max_outstandingdebt_522A', 'max_approvaldate_319D', 'max_dateactivated_425D', 'max_dtlastpmt_581D', 'max_dtlastpmtallstes_3545839D', 'max_employedfrom_700D', 'max_firstnonzeroinstldate_307D', 'max_byoccupationinc_3656910L', 'max_childnum_21L', 'max_pmtnum_8L', 'max_recorddate_4527225D', 'max_deductiondate_4917603D', 'max_pmtamount_36A', 'max_processingdate_168D', 'max_num_group1_5', 'max_credlmt_230A', 'max_credlmt_935A', 'max_dpdmax_139P', 'max_dpdmaxdatemonth_89T', 'max_dpdmaxdateyear_596T', 'max_pmts_dpd_303P', 'max_dpdmaxdatemonth_442T', 'max_dpdmaxdateyear_896T', 'max_instlamount_768A', 'max_monthlyinstlamount_332A', 'max_monthlyinstlamount_674A', 'max_outstandingamount_354A', 'max_outstandingamount_362A', 'max_overdueamount_31A', 'max_overdueamount_659A', 'max_numberofoverdueinstls_725L', 'max_overdueamountmax2_14A', 'max_totaloutstanddebtvalue_39A', 'max_dateofcredend_289D', 'max_dateofcredstart_739D', 'max_lastupdate_1112D', 'max_numberofcontrsvalue_258L', 'max_numberofoverdueinstlmax_1039L', 'max_overdueamountmaxdatemonth_365T', 'max_overdueamountmaxdateyear_2T', 'max_pmts_month_158T', 'max_pmts_year_1139T', 'max_overdueamountmax2_398A', 'max_dateofcredend_353D', 'max_dateofcredstart_181D', 'max_numberofoverdueinstlmax_1151L', 'max_overdueamountmax_35A', 'max_overdueamountmaxdatemonth_284T', 'max_overdueamountmaxdateyear_994T', 'max_residualamount_488A', 'max_residualamount_856A', 'max_totalamount_6A', 'max_totalamount_996A', 'max_totaldebtoverduevalue_718A', 'max_totaloutstanddebtvalue_668A', 'max_numberofcontrsvalue_358L', 'max_dateofrealrepmt_138D', 'max_lastupdate_388D', 'max_numberofoverdueinstlmaxdat_148D', 'max_numberofoverdueinstlmaxdat_641D', 'max_overdueamountmax2date_1002D', 'max_overdueamountmax2date_1142D', 'max_nominalrate_281L', 'max_nominalrate_498L', 'max_numberofinstls_229L', 'max_numberofinstls_320L', 'max_numberofoutstandinstls_520L', 'max_numberofoutstandinstls_59L', 'max_numberofoverdueinstls_834L', 'max_periodicityofpmts_1102L', 'max_periodicityofpmts_837L', 'max_num_group1_6', 'max_contractdate_551D', 'max_pmts_date_1107D', 'max_contractmaturitydate_151D', 'max_birthdate_87D', 'max_empl_employedfrom_271D', 'max_contractenddate_991D', 'max_openingdate_313D', 'max_openingdate_857D', 'max_collater_valueofguarantee_1124L', 'max_collater_valueofguarantee_876L', 'max_pmts_month_706T', 'max_pmts_year_507T', 'max_num_group1_13', 'max_num_group2_13', 'max_empls_employedfrom_796D', 'max_num_group1_15', 'max_num_group2_15']\n",
      "241\n",
      "306\n"
     ]
    }
   ],
   "source": [
    "df = feature_eng(**data_store) # import train data \n",
    "print(\"train data shape:\\t\", df.shape)\n",
    "# gc.collect()\n",
    "# spamming gc.collect praying for memory to not full\n",
    "gc.collect()\n",
    "df = df.pipe(Pipeline.filter_cols) # fillter column\n",
    "gc.collect()\n",
    "df, cat_cols = to_pandas(df) # tranform to pandas dataframe, easier to work with\n",
    "gc.collect()\n",
    "df = reduce_mem_usage(df) # as the name said\n",
    "gc.collect()\n",
    "print(\"train data shape:\\t\", df.shape)\n",
    "nums=df.select_dtypes(exclude='category').columns\n",
    "# IDK what is going on for now\n",
    "from itertools import combinations, permutations\n",
    "#df=df[nums]\n",
    "nans_df = df[nums].isna()\n",
    "nans_groups={}\n",
    "for col in nums:\n",
    "    cur_group = nans_df[col].sum()\n",
    "    try:\n",
    "        nans_groups[cur_group].append(col)\n",
    "    except:\n",
    "        nans_groups[cur_group]=[col]\n",
    "del nans_df; x=gc.collect()\n",
    "\n",
    "def reduce_group(grps):\n",
    "    use = []\n",
    "    for g in grps:\n",
    "        mx = 0; vx = g[0]\n",
    "        for gg in g:\n",
    "            n = df[gg].nunique()\n",
    "            if n>mx:\n",
    "                mx = n\n",
    "                vx = gg\n",
    "            #print(str(gg)+'-'+str(n),', ',end='')\n",
    "        use.append(vx)\n",
    "        #print()\n",
    "    print('Use these',use)\n",
    "    return use\n",
    "\n",
    "def group_columns_by_correlation(matrix, threshold=0.8):\n",
    "    correlation_matrix = matrix.corr()\n",
    "    groups = []\n",
    "    remaining_cols = list(matrix.columns)\n",
    "    while remaining_cols:\n",
    "        col = remaining_cols.pop(0)\n",
    "        group = [col]\n",
    "        correlated_cols = [col]\n",
    "        for c in remaining_cols:\n",
    "            if correlation_matrix.loc[col, c] >= threshold:\n",
    "                group.append(c)\n",
    "                correlated_cols.append(c)\n",
    "        groups.append(group)\n",
    "        remaining_cols = [c for c in remaining_cols if c not in correlated_cols]\n",
    "    return groups\n",
    "\n",
    "uses=[]\n",
    "for k,v in nans_groups.items():\n",
    "    if len(v)>1:\n",
    "            Vs = nans_groups[k]\n",
    "            #cross_features=list(combinations(Vs, 2))\n",
    "            #make_corr(Vs)\n",
    "            grps= group_columns_by_correlation(df[Vs], threshold=0.8)\n",
    "            use=reduce_group(grps)\n",
    "            uses=uses+use\n",
    "            #make_corr(use)\n",
    "    else:\n",
    "        uses=uses+v\n",
    "    print('####### NAN count =',k)\n",
    "print(uses)\n",
    "print(len(uses))\n",
    "uses=uses+list(df.select_dtypes(include='category').columns)\n",
    "print(len(uses))\n",
    "df=df[uses]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93fe797",
   "metadata": {
    "papermill": {
     "duration": 0.006268,
     "end_time": "2024-02-07T21:28:21.080353",
     "exception": false,
     "start_time": "2024-02-07T21:28:21.074085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36fca359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a82d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645ef447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_data = df.isnull().sum()\n",
    "# print(\"\\nMissing Data:\")\n",
    "# print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae3fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nCorrelation Matrix:\")\n",
    "# plt.figure(figsize=(15, 12))\n",
    "# sns.heatmap(df.corr(), fmt=\".2f\", cmap='coolwarm')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36b52589",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 12:03:07,167 - /home/sabina.jangirova/.conda/envs/ai701/lib/python3.8/site-packages/castle/backend/__init__.py[line:36] - INFO: You can use `os.environ['CASTLE_BACKEND'] = backend` to set the backend(`pytorch` or `mindspore`).\n",
      "2024-05-11 12:03:08,579 - /home/sabina.jangirova/.conda/envs/ai701/lib/python3.8/site-packages/castle/algorithms/__init__.py[line:36] - INFO: You are using ``pytorch`` as the backend.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import dowhy.gcm as gcm\n",
    "from castle.algorithms import PC\n",
    "from castle.algorithms.pc.pc import find_skeleton\n",
    "from castle.common import GraphDAG\n",
    "from castle.metrics import MetricsDAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d74998a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(input_graph, node_lookup):\n",
    "    '''\n",
    "    Function to visualise graphs.\n",
    "\n",
    "    Args:\n",
    "        input_graph (array): Adjacency matrix representing graph\n",
    "        node_lookup (dict): Dictionary containing node names.\n",
    "    '''\n",
    "    \n",
    "    graph = nx.DiGraph(input_graph)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    nx.draw(\n",
    "    G=graph,\n",
    "    node_color=COLORS[0],\n",
    "    node_size=8000,\n",
    "    arrowsize=17,\n",
    "    with_labels=True,\n",
    "    labels=node_lookup,\n",
    "    font_color='white',\n",
    "    font_size=9,\n",
    "    pos=nx.circular_layout(graph)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af9ce9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "df = df.drop(columns=[\"case_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f62b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols] = df[cat_cols].astype(str)\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Fit Ordinal Encoder on Training Data\n",
    "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=np.nan)\n",
    "encoder.fit(df[cat_cols])\n",
    "\n",
    "# Transform Training Data\n",
    "df[cat_cols] = encoder.transform(df[cat_cols])\n",
    "df[cat_cols] = df[cat_cols].fillna(-1)\n",
    "df[cat_cols] = df[cat_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d15fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6002083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "node_lookup = {i: column for i, column in enumerate(df.columns)}\n",
    "total_nodes = len(node_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ca1a9af",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b54d0e94",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59a959ed",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "weeks = X_train['WEEK_NUM']\n",
    "X_train = X_train.drop(columns=['WEEK_NUM'])\n",
    "X_test = X_test.drop(columns=['WEEK_NUM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4989e502",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b388f6b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 10,  \n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 2000,  \n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"random_state\": 42,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 10,\n",
    "    \"extra_trees\":True,\n",
    "    'num_leaves':64,\n",
    "    \"device_type\": \"cpu\", \n",
    "    \"verbose\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9807c627",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import time \n",
    "import resource\n",
    "\n",
    "def using():\n",
    "    usage=resource.getrusage(resource.RUSAGE_SELF)\n",
    "    return usage[2]/1024.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "334e0893",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 30178, number of negative: 947050\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37530\n",
      "[LightGBM] [Info] Number of data points in the train set: 977228, number of used features: 297\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030881 -> initscore=-3.446239\n",
      "[LightGBM] [Info] Start training from score -3.446239\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.842283\n",
      "[400]\tvalid_0's auc: 0.848083\n",
      "[600]\tvalid_0's auc: 0.850086\n",
      "[800]\tvalid_0's auc: 0.850895\n",
      "[1000]\tvalid_0's auc: 0.851333\n",
      "[1200]\tvalid_0's auc: 0.851478\n",
      "Early stopping, best iteration is:\n",
      "[1123]\tvalid_0's auc: 0.851489\n",
      "[LightGBM] [Info] Number of positive: 30985, number of negative: 946298\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.133426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37562\n",
      "[LightGBM] [Info] Number of data points in the train set: 977283, number of used features: 297\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031705 -> initscore=-3.419054\n",
      "[LightGBM] [Info] Start training from score -3.419054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.848584\n",
      "[400]\tvalid_0's auc: 0.854261\n",
      "[600]\tvalid_0's auc: 0.856319\n",
      "[800]\tvalid_0's auc: 0.857125\n",
      "[1000]\tvalid_0's auc: 0.857235\n",
      "[1200]\tvalid_0's auc: 0.857487\n",
      "Early stopping, best iteration is:\n",
      "[1251]\tvalid_0's auc: 0.857544\n",
      "[LightGBM] [Info] Number of positive: 31087, number of negative: 946197\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.133008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37591\n",
      "[LightGBM] [Info] Number of data points in the train set: 977284, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031810 -> initscore=-3.415661\n",
      "[LightGBM] [Info] Start training from score -3.415661\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.842769\n",
      "[400]\tvalid_0's auc: 0.848428\n",
      "[600]\tvalid_0's auc: 0.850445\n",
      "[800]\tvalid_0's auc: 0.85142\n",
      "[1000]\tvalid_0's auc: 0.85189\n",
      "[1200]\tvalid_0's auc: 0.852102\n",
      "[1400]\tvalid_0's auc: 0.852139\n",
      "Early stopping, best iteration is:\n",
      "[1341]\tvalid_0's auc: 0.852182\n",
      "[LightGBM] [Info] Number of positive: 30855, number of negative: 945600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.345416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37557\n",
      "[LightGBM] [Info] Number of data points in the train set: 976455, number of used features: 297\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031599 -> initscore=-3.422521\n",
      "[LightGBM] [Info] Start training from score -3.422521\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.849355\n",
      "[400]\tvalid_0's auc: 0.854778\n",
      "[600]\tvalid_0's auc: 0.856641\n",
      "[800]\tvalid_0's auc: 0.857589\n",
      "[1000]\tvalid_0's auc: 0.857802\n",
      "[1200]\tvalid_0's auc: 0.857934\n",
      "[1400]\tvalid_0's auc: 0.858018\n",
      "Early stopping, best iteration is:\n",
      "[1461]\tvalid_0's auc: 0.858059\n",
      "[LightGBM] [Info] Number of positive: 30659, number of negative: 946399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37569\n",
      "[LightGBM] [Info] Number of data points in the train set: 977058, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031379 -> initscore=-3.429738\n",
      "[LightGBM] [Info] Start training from score -3.429738\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.838095\n",
      "[400]\tvalid_0's auc: 0.843696\n",
      "[600]\tvalid_0's auc: 0.845759\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's auc: 0.8464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's auc: 0.84668\n",
      "[1200]\tvalid_0's auc: 0.846824\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1400]\tvalid_0's auc: 0.846847\n",
      "[1600]\tvalid_0's auc: 0.846908\n",
      "Early stopping, best iteration is:\n",
      "[1575]\tvalid_0's auc: 0.846959\n",
      "CV AUC scores:  [0.8514885806152537, 0.8575436957111151, 0.8521815466552063, 0.8580593047622842, 0.846959189430674]\n",
      "Maximum CV AUC score:  0.8580593047622842\n"
     ]
    }
   ],
   "source": [
    "fitted_models = []\n",
    "cv_scores = []\n",
    "lgbm_times = []\n",
    "lgbm_memory = []\n",
    "for idx_train, idx_valid in cv.split(X_train, y_train, groups=weeks):\n",
    "    X_train_l, y_train_l = X_train.iloc[idx_train], y_train.iloc[idx_train]\n",
    "    X_valid, y_valid = X_train.iloc[idx_valid], y_train.iloc[idx_valid]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    start_memory = using()\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train_l, y_train_l,\n",
    "        eval_set = [(X_valid, y_valid)],\n",
    "        callbacks = [lgb.log_evaluation(200), lgb.early_stopping(100)] )\n",
    "    lgbm_memory.append(start_memory-using())\n",
    "    lgbm_times.append(start_time-time.time())\n",
    "    fitted_models.append(model)\n",
    "    \n",
    "    y_pred_valid = model.predict_proba(X_valid)[:,1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores.append(auc_score)\n",
    "    \n",
    "print(\"CV AUC scores: \", cv_scores)\n",
    "print(\"Maximum CV AUC score: \", max(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9be9deb",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./saved_models/lgbm/lgbm_memory.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(fitted_models, \"./saved_models/lgbm/fitted_models.joblib\")\n",
    "dump(cv_scores, \"./saved_models/lgbm/cv_scores.joblib\")\n",
    "dump(lgbm_times, \"./saved_models/lgbm/lgbm_times.joblib\")\n",
    "dump(lgbm_memory, \"./saved_models/lgbm/lgbm_memory.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0d756bd",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/latex": [
       "$\\displaystyle \\left[ -172.266268730164, \\  -207.662727355957, \\  -201.804399967194, \\  -209.138760566711, \\  -231.932235717773\\right]$"
      ],
      "text/plain": [
       "[-172.26626873016357, -207.66272735595703, -201.8043999671936, -209.1387605667\n",
       "1143, -231.93223571777344]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fb2dfc7",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from sklearn.model_selection import StratifiedGroupKFold\n",
    "# import numpy as np\n",
    "\n",
    "# conf_matrix = None\n",
    "# class_report = None\n",
    "\n",
    "# # Predict labels for validation data\n",
    "# y_pred_labels = fitted_models[3].predict(X_test)\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred_labels)\n",
    "\n",
    "# # Compute classification report\n",
    "# class_report = classification_report(y_test, y_pred_labels)\n",
    "\n",
    "# # Print confusion matrix and classification report\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf97d0e9",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# lgb.plot_importance(fitted_models[3], importance_type=\"split\", figsize=(10,50))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a139e40",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# features = X_test.columns\n",
    "# importances = fitted_models[3].feature_importances_\n",
    "# feature_importance = pd.DataFrame({'importance':importances,'features':features}).sort_values('importance', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b40e3185",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# for f in feature_importance.iterrows():\n",
    "#     print(f)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7493015,
     "sourceId": 50160,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 145.018038,
   "end_time": "2024-02-07T21:30:18.166484",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-07T21:27:53.148446",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
